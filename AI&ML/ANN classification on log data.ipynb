{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn import model_selection\n",
    "from get_log_data import read_logs, get_digitized_logdata\n",
    "\n",
    "X_train, X_validation, Y_train, Y_validation=get_digitized_logdata(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "import utils\n",
    "\n",
    "# Define paramaters for the model\n",
    "\n",
    "np.random.seed(1337)\n",
    "learning_rate = 0.003\n",
    "batch_size = 960\n",
    "n_epochs = 630\n",
    "n_train = 15000\n",
    "n_test = 2000\n",
    "train=X_train,Y_train\n",
    "test=X_validation,Y_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14853, 7), (14853, 2), (1887, 2))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,Y_train.shape,Y_validation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 2: Create datasets and iterator\n",
    "train_data = tf.data.Dataset.from_tensor_slices(train)\n",
    "# train_data = train_data.shuffle(10000) # if you want to shuffle your data\n",
    "train_data = train_data.batch(batch_size)\n",
    "\n",
    "test_data = tf.data.Dataset.from_tensor_slices(test)\n",
    "test_data = test_data.batch(batch_size)\n",
    "\n",
    "iterator = tf.data.Iterator.from_structure(train_data.output_types, \n",
    "                                           train_data.output_shapes)\n",
    "img, label = iterator.get_next()\n",
    "\n",
    "train_init = iterator.make_initializer(train_data)\t# initializer for train_data\n",
    "test_init = iterator.make_initializer(test_data)\t# initializer for train_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-b24c59379dae>:50: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 3: create weights and bias\n",
    "# w is initialized to random variables with mean of 0, stddev of 0.01\n",
    "# b is initialized to 0\n",
    "# shape of w depends on the dimension of X and Y so that Y = tf.matmul(X, w)\n",
    "# shape of b depends on Y\n",
    "\n",
    "# w = tf.get_variable(name='weights', shape=(X_train.shape[1], Y_train.shape[1]), initializer=tf.random_normal_initializer(0, 0.001))\n",
    "# b = tf.get_variable(name='bias', shape=(1, Y_train.shape[1]), initializer=tf.zeros_initializer())\n",
    "nhidden0 = 160\n",
    "nhidden1 = 80\n",
    "nhidden2 = 40\n",
    "w0 = tf.get_variable(name='weights', shape=(X_train.shape[1], nhidden0), initializer=tf.random_normal_initializer(0, 0.001))\n",
    "b0 = tf.get_variable(name='bias', shape=(1, nhidden0), initializer=tf.zeros_initializer())\n",
    "\n",
    "\n",
    "w1 = tf.get_variable(name='weights1', shape=(nhidden0, nhidden1), initializer=tf.random_normal_initializer(0, 0.001))\n",
    "b1 = tf.get_variable(name='bias1', shape=(1, nhidden1), initializer=tf.zeros_initializer())\n",
    "\n",
    "w2 = tf.get_variable(name='weights2', shape=(nhidden1, nhidden2), initializer=tf.random_normal_initializer(0, 0.001))\n",
    "b2 = tf.get_variable(name='bias2', shape=(1, nhidden2), initializer=tf.zeros_initializer())\n",
    "\n",
    "wf = tf.get_variable(name='weightsf', shape=(nhidden2, Y_train.shape[1]), initializer=tf.random_normal_initializer(0, 0.001))\n",
    "bf = tf.get_variable(name='biasf', shape=(1, Y_train.shape[1]), initializer=tf.zeros_initializer())\n",
    "# #***************************************************\n",
    "\n",
    "# W0 = tf.Variable(tf.random_normal([2, nhidden],stddev=0.1))\n",
    "# b0 = tf.Variable(tf.zeros([nhidden]))\n",
    "\n",
    "# W1 = tf.Variable(tf.random_normal([nhidden, 1],stddev=0.1))\n",
    "# b1 = tf.Variable(tf.zeros([1]))\n",
    "\n",
    "hidden1 = tf.matmul(img, w0) + b0\n",
    "\n",
    "hidden2 = tf.matmul(hidden1, w1) + b1\n",
    "\n",
    "hiddenf = tf.matmul(hidden2, w2) + b2\n",
    "# yp = tf.matmul(tf.nn.relu(hidden), W1) + b1\n",
    "# logits = tf.nn.softmax(yp,dim=0)\n",
    "# #********************************************************\n",
    "\n",
    "# Step 4: build model\n",
    "# the model that returns the logits.\n",
    "# this logits will be later passed through softmax layer\n",
    "logits = tf.matmul(tf.nn.relu(hiddenf), wf) + bf\n",
    "\n",
    "# Step 5: define loss function\n",
    "# use cross entropy of softmax of logits as the loss function\n",
    "\n",
    "\n",
    "entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=label, name='entropy')\n",
    "loss = tf.reduce_mean(entropy, name='loss') # computes the mean over all the examples in the batch\n",
    "\n",
    "# Step 6: define training op\n",
    "# using gradient descent with learning rate of 0.01 to minimize loss\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "# optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "\n",
    "# Step 7: calculate accuracy with test set\n",
    "preds = tf.nn.softmax(logits)\n",
    "correct_preds = tf.equal(tf.argmax(preds, 1), tf.argmax(label, 1))\n",
    "accuracy = tf.reduce_sum(tf.cast(correct_preds, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss epoch 0: 0.6940217725932598 w1:0.010669725947082043\n",
      "Average loss epoch 1: 0.6703064385801554 w1:0.02415204606950283\n",
      "Average loss epoch 2: 0.643114760518074 w1:0.023635871708393097\n",
      "Average loss epoch 3: 0.6038780994713306 w1:0.026598386466503143\n",
      "Average loss epoch 4: 0.6216896465048194 w1:0.024096744135022163\n",
      "Average loss epoch 5: 0.6187548600137234 w1:0.023289533331990242\n",
      "Average loss epoch 6: 0.6208184938877821 w1:0.019895009696483612\n",
      "Average loss epoch 7: 0.613815113902092 w1:0.019222060218453407\n",
      "Average loss epoch 8: 0.621694952249527 w1:0.018081046640872955\n",
      "Average loss epoch 9: 0.6154240630567074 w1:0.01620233617722988\n",
      "Average loss epoch 10: 0.6091997735202312 w1:0.016921106725931168\n",
      "Average loss epoch 11: 0.5961907468736172 w1:0.015885602682828903\n",
      "Average loss epoch 12: 0.6077510854229331 w1:0.0139440493658185\n",
      "Average loss epoch 13: 0.5982673522084951 w1:0.012689372524619102\n",
      "Average loss epoch 14: 0.6047499226406217 w1:0.010942279361188412\n",
      "Average loss epoch 15: 0.5938661564141512 w1:0.010521342046558857\n",
      "Average loss epoch 16: 0.6014149095863104 w1:0.007994024083018303\n",
      "Average loss epoch 17: 0.5898548662662506 w1:0.007568515371531248\n",
      "Average loss epoch 18: 0.5969306658953428 w1:0.005897692870348692\n",
      "Average loss epoch 19: 0.5818457398563623 w1:0.006425119005143642\n",
      "Average loss epoch 20: 0.5903673805296421 w1:0.0032585496082901955\n",
      "Average loss epoch 21: 0.5768569726496935 w1:0.0053489841520786285\n",
      "Average loss epoch 22: 0.5798892555758357 w1:0.0047167642042040825\n",
      "Average loss epoch 23: 0.572117181494832 w1:0.006541906856000423\n",
      "Average loss epoch 24: 0.5822468483820558 w1:0.006012219935655594\n",
      "Average loss epoch 25: 0.56432687304914 w1:0.004559945780783892\n",
      "Average loss epoch 26: 0.5749596767127514 w1:0.0038360217586159706\n",
      "Average loss epoch 27: 0.568269319832325 w1:0.0032329484820365906\n",
      "Average loss epoch 28: 0.5657527018338442 w1:0.005241727456450462\n",
      "Average loss epoch 29: 0.5532468315213919 w1:0.0013406676007434726\n",
      "Average loss epoch 30: 0.5548953944817185 w1:0.002296170685440302\n",
      "Average loss epoch 31: 0.5480048339813948 w1:0.0012806530576199293\n",
      "Average loss epoch 32: 0.5466602081432939 w1:0.0009646808030083776\n",
      "Average loss epoch 33: 0.5371877830475569 w1:-0.0003156313323415816\n",
      "Average loss epoch 34: 0.5396283706650138 w1:0.0007471089484170079\n",
      "Average loss epoch 35: 0.5305246766656637 w1:0.0009837085381150246\n",
      "Average loss epoch 36: 0.5351234376430511 w1:0.0005376405315473676\n",
      "Average loss epoch 37: 0.5264939535409212 w1:0.0010252385400235653\n",
      "Average loss epoch 38: 0.5325527507811785 w1:-9.345205035060644e-05\n",
      "Average loss epoch 39: 0.5259078647941351 w1:-0.0001804519270081073\n",
      "Average loss epoch 40: 0.532070648856461 w1:-0.0018159695900976658\n",
      "Average loss epoch 41: 0.5311902444809675 w1:-0.0033522071316838264\n",
      "Average loss epoch 42: 0.5406918730586767 w1:-0.0019057809840887785\n",
      "Average loss epoch 43: 0.537077440880239 w1:-0.0024184775538742542\n",
      "Average loss epoch 44: 0.5333855953067541 w1:-0.002177528105676174\n",
      "Average loss epoch 45: 0.5256676264107227 w1:0.003300949465483427\n",
      "Average loss epoch 46: 0.5327123501338065 w1:-0.0028163515962660313\n",
      "Average loss epoch 47: 0.5368065424263477 w1:-0.00011932587949559093\n",
      "Average loss epoch 48: 0.527907551266253 w1:-0.009421391412615776\n",
      "Average loss epoch 49: 0.5242068162187934 w1:-0.006495675537735224\n",
      "Average loss epoch 50: 0.5282722469419241 w1:-0.002813717583194375\n",
      "Average loss epoch 51: 0.5418117064982653 w1:-0.0016576014459133148\n",
      "Average loss epoch 52: 0.5240090130828321 w1:-0.019168201833963394\n",
      "Average loss epoch 53: 0.5164157887920737 w1:-0.01789264939725399\n",
      "Average loss epoch 54: 0.5245924016926438 w1:-0.0075677791610360146\n",
      "Average loss epoch 55: 0.5384421590715647 w1:-0.002229034900665283\n",
      "Average loss epoch 56: 0.5071240444667637 w1:-0.0054769692942500114\n",
      "Average loss epoch 57: 0.5081285815685987 w1:-0.00755302794277668\n",
      "Average loss epoch 58: 0.5059477179311216 w1:-0.00908382423222065\n",
      "Average loss epoch 59: 0.5043738812673837 w1:-0.010062459856271744\n",
      "Average loss epoch 60: 0.5026490190066397 w1:-0.010473838075995445\n",
      "Average loss epoch 61: 0.5097247257363051 w1:-0.01251438818871975\n",
      "Average loss epoch 62: 0.5325225461274385 w1:-0.004357372410595417\n",
      "Average loss epoch 63: 0.5003904805053025 w1:-0.005563394166529179\n",
      "Average loss epoch 64: 0.5014317450113595 w1:-0.010093562304973602\n",
      "Average loss epoch 65: 0.502032556803897 w1:-0.012246998958289623\n",
      "Average loss epoch 66: 0.4994892447721213 w1:-0.01248181238770485\n",
      "Average loss epoch 67: 0.49104350549168885 w1:-0.01159901637583971\n",
      "Average loss epoch 68: 0.4877129294909537 w1:-0.010865386575460434\n",
      "Average loss epoch 69: 0.4883768795989454 w1:-0.012134242802858353\n",
      "Average loss epoch 70: 0.4915758497081697 w1:-0.01617291569709778\n",
      "Average loss epoch 71: 0.5064072217792273 w1:-0.020250540226697922\n",
      "Average loss epoch 72: 0.5594119783490896 w1:-0.02364121936261654\n",
      "Average loss epoch 73: 0.5192924987059087 w1:-0.029031718149781227\n",
      "Average loss epoch 74: 0.517788961995393 w1:-0.030670244246721268\n",
      "Average loss epoch 75: 0.5373257824685425 w1:-0.027922483161091805\n",
      "Average loss epoch 76: 0.5565119106322527 w1:-0.0329529270529747\n",
      "Average loss epoch 77: 0.5250438433140516 w1:-0.03725256770849228\n",
      "Average loss epoch 78: 0.5224242825061083 w1:-0.039222169667482376\n",
      "Average loss epoch 79: 0.5215397533029318 w1:-0.041765887290239334\n",
      "Average loss epoch 80: 0.5154960677027702 w1:-0.043657440692186356\n",
      "Average loss epoch 81: 0.5193931488320231 w1:-0.045261673629283905\n",
      "Average loss epoch 82: 0.511538190767169 w1:-0.04649205878376961\n",
      "Average loss epoch 83: 0.5239178193733096 w1:-0.04520725831389427\n",
      "Average loss epoch 84: 0.5113399215042591 w1:-0.05016385763883591\n",
      "Average loss epoch 85: 0.5284932088106871 w1:-0.04688877612352371\n",
      "Average loss epoch 86: 0.5138504169881344 w1:-0.05350017175078392\n",
      "Average loss epoch 87: 0.5173457823693752 w1:-0.05354570597410202\n",
      "Average loss epoch 88: 0.5076038725674152 w1:-0.05480391904711723\n",
      "Average loss epoch 89: 0.5280503015965223 w1:-0.05103036388754845\n",
      "Average loss epoch 90: 0.5199407562613487 w1:-0.05825906991958618\n",
      "Average loss epoch 91: 0.5020751655101776 w1:-0.06073019281029701\n",
      "Average loss epoch 92: 0.48888850305229425 w1:-0.06364890187978745\n",
      "Average loss epoch 93: 0.49101990507915616 w1:-0.0610729418694973\n",
      "Average loss epoch 94: 0.491183094214648 w1:-0.06157754734158516\n",
      "Average loss epoch 95: 0.5027967807836831 w1:-0.05917923524975777\n",
      "Average loss epoch 96: 0.5284557957202196 w1:-0.07208133488893509\n",
      "Average loss epoch 97: 0.5279110614210367 w1:-0.0826219916343689\n",
      "Average loss epoch 98: 0.5046300506219268 w1:-0.0902000144124031\n",
      "Average loss epoch 99: 0.5108695225790143 w1:-0.09148569405078888\n",
      "Average loss epoch 100: 0.5147893922403455 w1:-0.08908788859844208\n",
      "Average loss epoch 101: 0.4906131215393543 w1:-0.09162893146276474\n",
      "Average loss epoch 102: 0.5291657727211714 w1:-0.10204874724149704\n",
      "Average loss epoch 103: 0.5088091306388378 w1:-0.08663006126880646\n",
      "Average loss epoch 104: 0.5196467936038971 w1:-0.08970187604427338\n",
      "Average loss epoch 105: 0.5156184174120426 w1:-0.0806749239563942\n",
      "Average loss epoch 106: 0.5559189328923821 w1:-0.0777115747332573\n",
      "Average loss epoch 107: 0.5009405221790075 w1:-0.07146745920181274\n",
      "Average loss epoch 108: 0.49209474329836667 w1:-0.07906833291053772\n",
      "Average loss epoch 109: 0.4803814012557268 w1:-0.07828564941883087\n",
      "Average loss epoch 110: 0.48734697652980685 w1:-0.08997652679681778\n",
      "Average loss epoch 111: 0.493712592869997 w1:-0.07357949763536453\n",
      "Average loss epoch 112: 0.48243178986012936 w1:-0.07721848785877228\n",
      "Average loss epoch 113: 0.4688387680798769 w1:-0.09371963888406754\n",
      "Average loss epoch 114: 0.4642092047724873 w1:-0.09921500086784363\n",
      "Average loss epoch 115: 0.4613861748948693 w1:-0.09184114634990692\n",
      "Average loss epoch 116: 0.4637316253501922 w1:-0.10280479490756989\n",
      "Average loss epoch 117: 0.45670703588984907 w1:-0.10075026005506516\n",
      "Average loss epoch 118: 0.45581392431631684 w1:-0.10504436492919922\n",
      "Average loss epoch 119: 0.45372912543825805 w1:-0.09308908879756927\n",
      "Average loss epoch 120: 0.455003626877442 w1:-0.09908175468444824\n",
      "Average loss epoch 121: 0.45364656345918775 w1:-0.09290085732936859\n",
      "Average loss epoch 122: 0.45384725416079164 w1:-0.09713967144489288\n",
      "Average loss epoch 123: 0.46217151917517185 w1:-0.09115064889192581\n",
      "Average loss epoch 124: 0.4627913769800216 w1:-0.09504063427448273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss epoch 125: 0.4635488926433027 w1:-0.08752734214067459\n",
      "Average loss epoch 126: 0.458965826081112 w1:-0.09138533473014832\n",
      "Average loss epoch 127: 0.4515968728810549 w1:-0.09106430411338806\n",
      "Average loss epoch 128: 0.4476537087466568 w1:-0.09257745742797852\n",
      "Average loss epoch 129: 0.4427587687969208 w1:-0.087983138859272\n",
      "Average loss epoch 130: 0.44334696512669325 w1:-0.09211920201778412\n",
      "Average loss epoch 131: 0.4396635047160089 w1:-0.08920591324567795\n",
      "Average loss epoch 132: 0.4419886264950037 w1:-0.0920037105679512\n",
      "Average loss epoch 133: 0.4413481834344566 w1:-0.08810856938362122\n",
      "Average loss epoch 134: 0.44818978593684733 w1:-0.09028054028749466\n",
      "Average loss epoch 135: 0.44754065200686455 w1:-0.0865744948387146\n",
      "Average loss epoch 136: 0.45697357202880085 w1:-0.08694615215063095\n",
      "Average loss epoch 137: 0.4501534625887871 w1:-0.08832346647977829\n",
      "Average loss epoch 138: 0.4541026975493878 w1:-0.08738245069980621\n",
      "Average loss epoch 139: 0.4438055814243853 w1:-0.0851123109459877\n",
      "Average loss epoch 140: 0.44028056925162673 w1:-0.08802440762519836\n",
      "Average loss epoch 141: 0.4346592565998435 w1:-0.08635800331830978\n",
      "Average loss epoch 142: 0.4354132099542767 w1:-0.08618703484535217\n",
      "Average loss epoch 143: 0.4375520453322679 w1:-0.08569884300231934\n",
      "Average loss epoch 144: 0.4329508380033076 w1:-0.09071609377861023\n",
      "Average loss epoch 145: 0.4422894651070237 w1:-0.08793460577726364\n",
      "Average loss epoch 146: 0.442258779425174 w1:-0.08813852816820145\n",
      "Average loss epoch 147: 0.44593349006026983 w1:-0.08332859724760056\n",
      "Average loss epoch 148: 0.43601336516439915 w1:-0.08385881036520004\n",
      "Average loss epoch 149: 0.4584981915540993 w1:-0.0834922268986702\n",
      "Average loss epoch 150: 0.4368255907902494 w1:-0.09228114783763885\n",
      "Average loss epoch 151: 0.4727972401306033 w1:-0.08554668724536896\n",
      "Average loss epoch 152: 0.45636420045048 w1:-0.08042033761739731\n",
      "Average loss epoch 153: 0.46865441161207855 w1:-0.08076025545597076\n",
      "Average loss epoch 154: 0.4460296705365181 w1:-0.08927265554666519\n",
      "Average loss epoch 155: 0.44713379023596644 w1:-0.0892724022269249\n",
      "Average loss epoch 156: 0.4319714844459668 w1:-0.08909055590629578\n",
      "Average loss epoch 157: 0.43766499077901244 w1:-0.08539421856403351\n",
      "Average loss epoch 158: 0.43347605038434267 w1:-0.08838943392038345\n",
      "Average loss epoch 159: 0.4366663061082363 w1:-0.08749021589756012\n",
      "Average loss epoch 160: 0.427892271312885 w1:-0.08822189271450043\n",
      "Average loss epoch 161: 0.4320250393357128 w1:-0.08519712835550308\n",
      "Average loss epoch 162: 0.4226374046411365 w1:-0.08744507282972336\n",
      "Average loss epoch 163: 0.4287856388837099 w1:-0.08444046974182129\n",
      "Average loss epoch 164: 0.4198817528085783 w1:-0.08617047965526581\n",
      "Average loss epoch 165: 0.4312646039761603 w1:-0.08251730352640152\n",
      "Average loss epoch 166: 0.4207633101614192 w1:-0.08560187369585037\n",
      "Average loss epoch 167: 0.43322813557460904 w1:-0.08346755057573318\n",
      "Average loss epoch 168: 0.42142493464052677 w1:-0.08401802182197571\n",
      "Average loss epoch 169: 0.42854329547844827 w1:-0.0803256705403328\n",
      "Average loss epoch 170: 0.4239489664323628 w1:-0.08054806292057037\n",
      "Average loss epoch 171: 0.42829862679354846 w1:-0.08076823502779007\n",
      "Average loss epoch 172: 0.4308372335508466 w1:-0.07828599959611893\n",
      "Average loss epoch 173: 0.435871547088027 w1:-0.07597661763429642\n",
      "Average loss epoch 174: 0.43199499358888716 w1:-0.0742318332195282\n",
      "Average loss epoch 175: 0.4278287277556956 w1:-0.07394681125879288\n",
      "Average loss epoch 176: 0.42188504326622933 w1:-0.07315656542778015\n",
      "Average loss epoch 177: 0.4332513655535877 w1:-0.07443464547395706\n",
      "Average loss epoch 178: 0.4237801574636251 w1:-0.073693186044693\n",
      "Average loss epoch 179: 0.472363636828959 w1:-0.06701365113258362\n",
      "Average loss epoch 180: 0.4296994034666568 w1:-0.058306172490119934\n",
      "Average loss epoch 181: 0.4328186260536313 w1:-0.06157198175787926\n",
      "Average loss epoch 182: 0.4197921232553199 w1:-0.06679638475179672\n",
      "Average loss epoch 183: 0.42122289165854454 w1:-0.06250070035457611\n",
      "Average loss epoch 184: 0.4472999644931406 w1:-0.060419049113988876\n",
      "Average loss epoch 185: 0.4612534251064062 w1:-0.06673280149698257\n",
      "Average loss epoch 186: 0.4252773600164801 w1:-0.07128655910491943\n",
      "Average loss epoch 187: 0.4243958224542439 w1:-0.06725476682186127\n",
      "Average loss epoch 188: 0.42024914524517953 w1:-0.06852859258651733\n",
      "Average loss epoch 189: 0.4440498580224812 w1:-0.06612647324800491\n",
      "Average loss epoch 190: 0.5260811750777066 w1:-0.0633726641535759\n",
      "Average loss epoch 191: 0.5642951084300876 w1:-0.054809607565402985\n",
      "Average loss epoch 192: 0.5227601993829012 w1:-0.04747960716485977\n",
      "Average loss epoch 193: 0.4763339962810278 w1:-0.03784800320863724\n",
      "Average loss epoch 194: 0.4515678007155657 w1:-0.029440604150295258\n",
      "Average loss epoch 195: 0.43356409948319197 w1:-0.03551006689667702\n",
      "Average loss epoch 196: 0.4404356046579778 w1:-0.032182611525058746\n",
      "Average loss epoch 197: 0.43634637678042054 w1:-0.037883274257183075\n",
      "Average loss epoch 198: 0.4446556919720024 w1:-0.03764104098081589\n",
      "Average loss epoch 199: 0.45037967804819345 w1:-0.03833506628870964\n",
      "Average loss epoch 200: 0.45701531833037734 w1:-0.040296513587236404\n",
      "Average loss epoch 201: 0.43803750164806843 w1:-0.02995781973004341\n",
      "Average loss epoch 202: 0.43224416580051184 w1:-0.03573210537433624\n",
      "Average loss epoch 203: 0.4319284020457417 w1:-0.03348344936966896\n",
      "Average loss epoch 204: 0.424818302039057 w1:-0.04000922292470932\n",
      "Average loss epoch 205: 0.4305799894500524 w1:-0.03600351884961128\n",
      "Average loss epoch 206: 0.42159438179805875 w1:-0.03971361368894577\n",
      "Average loss epoch 207: 0.4283253592438996 w1:-0.03760777413845062\n",
      "Average loss epoch 208: 0.4242167789489031 w1:-0.038346417248249054\n",
      "Average loss epoch 209: 0.4290874651633203 w1:-0.03700836002826691\n",
      "Average loss epoch 210: 0.4213679637759924 w1:-0.03617472946643829\n",
      "Average loss epoch 211: 0.4164520155172795 w1:-0.03734401986002922\n",
      "Average loss epoch 212: 0.4193615228869021 w1:-0.03677418455481529\n",
      "Average loss epoch 213: 0.4156173674855381 w1:-0.03932696208357811\n",
      "Average loss epoch 214: 0.4279074207879603 w1:-0.03552104905247688\n",
      "Average loss epoch 215: 0.41765777207911015 w1:-0.040958888828754425\n",
      "Average loss epoch 216: 0.4279858358204365 w1:-0.03549262508749962\n",
      "Average loss epoch 217: 0.4141706549562514 w1:-0.04058557748794556\n",
      "Average loss epoch 218: 0.423013249412179 w1:-0.03802618756890297\n",
      "Average loss epoch 219: 0.4190767442341894 w1:-0.039737120270729065\n",
      "Average loss epoch 220: 0.4360894379206002 w1:-0.0361369363963604\n",
      "Average loss epoch 221: 0.44393199984915555 w1:-0.034543294459581375\n",
      "Average loss epoch 222: 0.46711272606626153 w1:-0.03232206776738167\n",
      "Average loss epoch 223: 0.45741847110912204 w1:-0.032126568257808685\n",
      "Average loss epoch 224: 0.4496066137216985 w1:-0.03582952544093132\n",
      "Average loss epoch 225: 0.43522710795514286 w1:-0.03831051290035248\n",
      "Average loss epoch 226: 0.4337490350008011 w1:-0.03450272977352142\n",
      "Average loss epoch 227: 0.43688975740224123 w1:-0.033540550619363785\n",
      "Average loss epoch 228: 0.4323252812027931 w1:-0.026512322947382927\n",
      "Average loss epoch 229: 0.4150190092623234 w1:-0.02892778068780899\n",
      "Average loss epoch 230: 0.41682365722954273 w1:-0.026366230100393295\n",
      "Average loss epoch 231: 0.40548964869230986 w1:-0.02977936342358589\n",
      "Average loss epoch 232: 0.40866094874218106 w1:-0.02765975147485733\n",
      "Average loss epoch 233: 0.4024135696236044 w1:-0.02945481427013874\n",
      "Average loss epoch 234: 0.40700298664160073 w1:-0.027092110365629196\n",
      "Average loss epoch 235: 0.4012477337382734 w1:-0.028664490208029747\n",
      "Average loss epoch 236: 0.4073576801456511 w1:-0.026752715930342674\n",
      "Average loss epoch 237: 0.4004354355856776 w1:-0.02876376360654831\n",
      "Average loss epoch 238: 0.4065945593174547 w1:-0.02754191868007183\n",
      "Average loss epoch 239: 0.4005527878180146 w1:-0.028945330530405045\n",
      "Average loss epoch 240: 0.40808675554580986 w1:-0.027973856776952744\n",
      "Average loss epoch 241: 0.4072664179839194 w1:-0.028117865324020386\n",
      "Average loss epoch 242: 0.42121600615791976 w1:-0.026577023789286613\n",
      "Average loss epoch 243: 0.42494610231369734 w1:-0.02492438443005085\n",
      "Average loss epoch 244: 0.4215349901933223 w1:-0.021894318982958794\n",
      "Average loss epoch 245: 0.4358275099657476 w1:-0.016775881871581078\n",
      "Average loss epoch 246: 0.41506463708356023 w1:-0.01531908567994833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss epoch 247: 0.41070033772848547 w1:-0.014718783088028431\n",
      "Average loss epoch 248: 0.39948245231062174 w1:-0.019413504749536514\n",
      "Average loss epoch 249: 0.40228244266472757 w1:-0.01950002834200859\n",
      "Average loss epoch 250: 0.39645337336696684 w1:-0.020373664796352386\n",
      "Average loss epoch 251: 0.40251610497944057 w1:-0.019236866384744644\n",
      "Average loss epoch 252: 0.39669902226887643 w1:-0.018048634752631187\n",
      "Average loss epoch 253: 0.4110218440182507 w1:-0.01663597673177719\n",
      "Average loss epoch 254: 0.41567975981161 w1:-0.015304545871913433\n",
      "Average loss epoch 255: 0.4199371936265379 w1:-0.015993090346455574\n",
      "Average loss epoch 256: 0.4234854537062347 w1:-0.012778625823557377\n",
      "Average loss epoch 257: 0.44960095966234803 w1:-0.011182301677763462\n",
      "Average loss epoch 258: 0.429100776091218 w1:-0.007237846963107586\n",
      "Average loss epoch 259: 0.42455354472622275 w1:-0.010551616549491882\n",
      "Average loss epoch 260: 0.4258428756147623 w1:-0.0021450205240398645\n",
      "Average loss epoch 261: 0.4077325169928372 w1:-0.0021775641944259405\n",
      "Average loss epoch 262: 0.40684656566008925 w1:-0.00249718246050179\n",
      "Average loss epoch 263: 0.39836500957608223 w1:-0.00354687194339931\n",
      "Average loss epoch 264: 0.4114868785254657 w1:-0.0016640507383272052\n",
      "Average loss epoch 265: 0.4088650899939239 w1:0.001190625480376184\n",
      "Average loss epoch 266: 0.44206542428582907 w1:0.0038371782284229994\n",
      "Average loss epoch 267: 0.4181038406677544 w1:0.007184497080743313\n",
      "Average loss epoch 268: 0.408730155788362 w1:0.005827741697430611\n",
      "Average loss epoch 269: 0.39951871638186276 w1:0.002668589586392045\n",
      "Average loss epoch 270: 0.40585452038794756 w1:0.003817579010501504\n",
      "Average loss epoch 271: 0.4019005545414984 w1:0.00528409518301487\n",
      "Average loss epoch 272: 0.41527438536286354 w1:0.008177641779184341\n",
      "Average loss epoch 273: 0.4052599079441279 w1:0.009328753687441349\n",
      "Average loss epoch 274: 0.41923524998128414 w1:0.007744939066469669\n",
      "Average loss epoch 275: 0.40301862685009837 w1:0.007697397843003273\n",
      "Average loss epoch 276: 0.40484265331178904 w1:0.008318123407661915\n",
      "Average loss epoch 277: 0.39591718814335763 w1:0.008067719638347626\n",
      "Average loss epoch 278: 0.41011543245986104 w1:0.009160628542304039\n",
      "Average loss epoch 279: 0.3998783908318728 w1:0.008537333458662033\n",
      "Average loss epoch 280: 0.40301926154643297 w1:0.010186922736465931\n",
      "Average loss epoch 281: 0.39948060316964984 w1:0.012694871984422207\n",
      "Average loss epoch 282: 0.41975564137101173 w1:0.013149719685316086\n",
      "Average loss epoch 283: 0.40563093731179833 w1:0.012256553396582603\n",
      "Average loss epoch 284: 0.4159834710881114 w1:0.009604125283658504\n",
      "Average loss epoch 285: 0.4081650897860527 w1:0.0113892313092947\n",
      "Average loss epoch 286: 0.4240750316530466 w1:0.015322979539632797\n",
      "Average loss epoch 287: 0.40854446101002395 w1:0.014625370502471924\n",
      "Average loss epoch 288: 0.4204760123975575 w1:0.011013091541826725\n",
      "Average loss epoch 289: 0.41592972236685455 w1:0.011242571286857128\n",
      "Average loss epoch 290: 0.4238382941111922 w1:0.015110823325812817\n",
      "Average loss epoch 291: 0.41212479304522276 w1:0.015035770833492279\n",
      "Average loss epoch 292: 0.40153466537594795 w1:0.015956806018948555\n",
      "Average loss epoch 293: 0.4010931102093309 w1:0.0179505106061697\n",
      "Average loss epoch 294: 0.4009690028615296 w1:0.019266989082098007\n",
      "Average loss epoch 295: 0.3987032053992152 w1:0.01623578369617462\n",
      "Average loss epoch 296: 0.4010247578844428 w1:0.01596948690712452\n",
      "Average loss epoch 297: 0.40286641428247094 w1:0.02023574709892273\n",
      "Average loss epoch 298: 0.42273101955652237 w1:0.02278060093522072\n",
      "Average loss epoch 299: 0.4208061289973557 w1:0.022421332076191902\n",
      "Average loss epoch 300: 0.4133929517120123 w1:0.011326724663376808\n",
      "Average loss epoch 301: 0.4188387142494321 w1:0.015346412546932697\n",
      "Average loss epoch 302: 0.4208351857960224 w1:0.02125515043735504\n",
      "Average loss epoch 303: 0.43813079153187573 w1:0.024321097880601883\n",
      "Average loss epoch 304: 0.4194009369239211 w1:0.023374663665890694\n",
      "Average loss epoch 305: 0.4361657921690494 w1:0.02757621929049492\n",
      "Average loss epoch 306: 0.42795351427048445 w1:0.03461186960339546\n",
      "Average loss epoch 307: 0.4221858822274953 w1:0.03367362171411514\n",
      "Average loss epoch 308: 0.40230764262378216 w1:0.036319613456726074\n",
      "Average loss epoch 309: 0.40902343951165676 w1:0.032418765127658844\n",
      "Average loss epoch 310: 0.41000694409012794 w1:0.029251065105199814\n",
      "Average loss epoch 311: 0.41110761370509863 w1:0.03279570862650871\n",
      "Average loss epoch 312: 0.4125624098815024 w1:0.032027654349803925\n",
      "Average loss epoch 313: 0.3982931333594024 w1:0.03342338651418686\n",
      "Average loss epoch 314: 0.40202433057129383 w1:0.028589852154254913\n",
      "Average loss epoch 315: 0.3849961291998625 w1:0.02718058042228222\n",
      "Average loss epoch 316: 0.38509022793732584 w1:0.03000372275710106\n",
      "Average loss epoch 317: 0.37915657623670995 w1:0.02907566912472248\n",
      "Average loss epoch 318: 0.38230671803466976 w1:0.02905324101448059\n",
      "Average loss epoch 319: 0.37972485297359526 w1:0.028789669275283813\n",
      "Average loss epoch 320: 0.3880484669934958 w1:0.026903443038463593\n",
      "Average loss epoch 321: 0.39354397100396454 w1:0.023612622171640396\n",
      "Average loss epoch 322: 0.3988204998895526 w1:0.026825476437807083\n",
      "Average loss epoch 323: 0.3931926228106022 w1:0.02728947438299656\n",
      "Average loss epoch 324: 0.39041295810602605 w1:0.026816733181476593\n",
      "Average loss epoch 325: 0.40133290318772197 w1:0.02716754749417305\n",
      "Average loss epoch 326: 0.40984685136936605 w1:0.03181174769997597\n",
      "Average loss epoch 327: 0.43677648855373263 w1:0.030871134251356125\n",
      "Average loss epoch 328: 0.40638850373215973 w1:0.032682694494724274\n",
      "Average loss epoch 329: 0.3863885479513556 w1:0.03496716171503067\n",
      "Average loss epoch 330: 0.3844358257483691 w1:0.03457829728722572\n",
      "Average loss epoch 331: 0.3820737488567829 w1:0.035716600716114044\n",
      "Average loss epoch 332: 0.3795490765478462 w1:0.038165751844644547\n",
      "Average loss epoch 333: 0.3871062626130879 w1:0.0373925119638443\n",
      "Average loss epoch 334: 0.3849063622765243 w1:0.03506488725543022\n",
      "Average loss epoch 335: 0.3870203006081283 w1:0.032508332282304764\n",
      "Average loss epoch 336: 0.39683473529294133 w1:0.03128806874155998\n",
      "Average loss epoch 337: 0.4009205943439156 w1:0.03458685055375099\n",
      "Average loss epoch 338: 0.4022910282947123 w1:0.03378528729081154\n",
      "Average loss epoch 339: 0.3981837988831103 w1:0.03376201540231705\n",
      "Average loss epoch 340: 0.41337811248376966 w1:0.03195064887404442\n",
      "Average loss epoch 341: 0.42190168774686754 w1:0.03695958852767944\n",
      "Average loss epoch 342: 0.4296976407058537 w1:0.03275668993592262\n",
      "Average loss epoch 343: 0.39899068302474916 w1:0.03603249043226242\n",
      "Average loss epoch 344: 0.3803929463028908 w1:0.041214946657419205\n",
      "Average loss epoch 345: 0.3806884731166065 w1:0.03892543166875839\n",
      "Average loss epoch 346: 0.38326281774789095 w1:0.03982493653893471\n",
      "Average loss epoch 347: 0.37532154913060367 w1:0.03914172947406769\n",
      "Average loss epoch 348: 0.38616613927297294 w1:0.04001275822520256\n",
      "Average loss epoch 349: 0.3917701712343842 w1:0.03997068107128143\n",
      "Average loss epoch 350: 0.40859508235007524 w1:0.03179934620857239\n",
      "Average loss epoch 351: 0.39951348467729986 w1:0.0352281779050827\n",
      "Average loss epoch 352: 0.40083483094349504 w1:0.040058683604002\n",
      "Average loss epoch 353: 0.3975789116229862 w1:0.040769848972558975\n",
      "Average loss epoch 354: 0.39376115007326007 w1:0.03372744098305702\n",
      "Average loss epoch 355: 0.39043871010653675 w1:0.03160008415579796\n",
      "Average loss epoch 356: 0.40621047373861074 w1:0.036574769765138626\n",
      "Average loss epoch 357: 0.4139323078561574 w1:0.048086997121572495\n",
      "Average loss epoch 358: 0.398488910170272 w1:0.04744376614689827\n",
      "Average loss epoch 359: 0.3982138456776738 w1:0.034734491258859634\n",
      "Average loss epoch 360: 0.40104647842235863 w1:0.027377936989068985\n",
      "Average loss epoch 361: 0.3981941968668252 w1:0.03451720252633095\n",
      "Average loss epoch 362: 0.4078143385704607 w1:0.035303909331560135\n",
      "Average loss epoch 363: 0.40294936392456293 w1:0.03660658746957779\n",
      "Average loss epoch 364: 0.3864849181845784 w1:0.040276024490594864\n",
      "Average loss epoch 365: 0.38530192780308425 w1:0.03753066435456276\n",
      "Average loss epoch 366: 0.3898586784489453 w1:0.03547542169690132\n",
      "Average loss epoch 367: 0.38413409260101616 w1:0.03964600712060928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss epoch 368: 0.3959283959120512 w1:0.03899442404508591\n",
      "Average loss epoch 369: 0.39926377101801336 w1:0.03983676806092262\n",
      "Average loss epoch 370: 0.388464636169374 w1:0.03845972195267677\n",
      "Average loss epoch 371: 0.37978445598855615 w1:0.030081838369369507\n",
      "Average loss epoch 372: 0.3896547141484916 w1:0.024735817685723305\n",
      "Average loss epoch 373: 0.3944730560760945 w1:0.03502757102251053\n",
      "Average loss epoch 374: 0.40576712926849723 w1:0.03731343522667885\n",
      "Average loss epoch 375: 0.3997050621546805 w1:0.04167180135846138\n",
      "Average loss epoch 376: 0.38568681944161654 w1:0.042351555079221725\n",
      "Average loss epoch 377: 0.3772180525120348 w1:0.03731011599302292\n",
      "Average loss epoch 378: 0.38021267275325954 w1:0.03645487129688263\n",
      "Average loss epoch 379: 0.3743957120459527 w1:0.0368412546813488\n",
      "Average loss epoch 380: 0.3800802263431251 w1:0.03417016938328743\n",
      "Average loss epoch 381: 0.3775295470841229 w1:0.03621817007660866\n",
      "Average loss epoch 382: 0.3859411512967199 w1:0.03906724229454994\n",
      "Average loss epoch 383: 0.38393413089215755 w1:0.03506254404783249\n",
      "Average loss epoch 384: 0.39248200762085617 w1:0.028511451557278633\n",
      "Average loss epoch 385: 0.3841588997747749 w1:0.033740028738975525\n",
      "Average loss epoch 386: 0.39478980423882604 w1:0.0339449979364872\n",
      "Average loss epoch 387: 0.39226738060824573 w1:0.04122119024395943\n",
      "Average loss epoch 388: 0.3933346173726022 w1:0.04265974462032318\n",
      "Average loss epoch 389: 0.3882196063641459 w1:0.0358835868537426\n",
      "Average loss epoch 390: 0.389402330853045 w1:0.03251050412654877\n",
      "Average loss epoch 391: 0.3842223905958235 w1:0.03613399341702461\n",
      "Average loss epoch 392: 0.4133194808382541 w1:0.03373290225863457\n",
      "Average loss epoch 393: 0.4173863297328353 w1:0.03404140844941139\n",
      "Average loss epoch 394: 0.4026583305094391 w1:0.028592107817530632\n",
      "Average loss epoch 395: 0.3860422077123076 w1:0.023307310417294502\n",
      "Average loss epoch 396: 0.3992438989225775 w1:0.023501425981521606\n",
      "Average loss epoch 397: 0.39161216374486685 w1:0.03236551582813263\n",
      "Average loss epoch 398: 0.39524196926504374 w1:0.03939162194728851\n",
      "Average loss epoch 399: 0.39952327124774456 w1:0.03541857376694679\n",
      "Average loss epoch 400: 0.38750206981785595 w1:0.02533276379108429\n",
      "Average loss epoch 401: 0.381327852839604 w1:0.035216283053159714\n",
      "Average loss epoch 402: 0.4030881649814546 w1:0.02630016952753067\n",
      "Average loss epoch 403: 0.3863368178717792 w1:0.02987864427268505\n",
      "Average loss epoch 404: 0.37727434118278325 w1:0.03408921882510185\n",
      "Average loss epoch 405: 0.3717785270418972 w1:0.03186850622296333\n",
      "Average loss epoch 406: 0.36381248058751225 w1:0.03298647329211235\n",
      "Average loss epoch 407: 0.37388430815190077 w1:0.03294244408607483\n",
      "Average loss epoch 408: 0.3885448658838868 w1:0.03637165576219559\n",
      "Average loss epoch 409: 0.3831882190424949 w1:0.03687593713402748\n",
      "Average loss epoch 410: 0.39858966669999063 w1:0.0236778873950243\n",
      "Average loss epoch 411: 0.3929973621852696 w1:0.03370198234915733\n",
      "Average loss epoch 412: 0.4022350755985826 w1:0.027987204492092133\n",
      "Average loss epoch 413: 0.3862777091562748 w1:0.030510863289237022\n",
      "Average loss epoch 414: 0.3706351008731872 w1:0.03482471778988838\n",
      "Average loss epoch 415: 0.38282672758214176 w1:0.032058119773864746\n",
      "Average loss epoch 416: 0.39849538216367364 w1:0.04036626219749451\n",
      "Average loss epoch 417: 0.40763031831011176 w1:0.04116452857851982\n",
      "Average loss epoch 418: 0.4325726078823209 w1:0.024895133450627327\n",
      "Average loss epoch 419: 0.4089952304493636 w1:0.02180125005543232\n",
      "Average loss epoch 420: 0.41970203537493944 w1:0.01644063927233219\n",
      "Average loss epoch 421: 0.3867784761823714 w1:0.01859738677740097\n",
      "Average loss epoch 422: 0.3688595884013921 w1:0.024545345455408096\n",
      "Average loss epoch 423: 0.3908770908601582 w1:0.027786361053586006\n",
      "Average loss epoch 424: 0.39789768122136593 w1:0.030543696135282516\n",
      "Average loss epoch 425: 0.40376073820516467 w1:0.030271071940660477\n",
      "Average loss epoch 426: 0.41475289035588503 w1:0.022674141451716423\n",
      "Average loss epoch 427: 0.4018004019744694 w1:0.025123996660113335\n",
      "Average loss epoch 428: 0.4166095252148807 w1:0.026646170765161514\n",
      "Average loss epoch 429: 0.37349776667542756 w1:0.027849499136209488\n",
      "Average loss epoch 430: 0.36430233460851014 w1:0.03065004013478756\n",
      "Average loss epoch 431: 0.36857245839200914 w1:0.026932280510663986\n",
      "Average loss epoch 432: 0.3607650294434279 w1:0.033778101205825806\n",
      "Average loss epoch 433: 0.3708391229156405 w1:0.026568366214632988\n",
      "Average loss epoch 434: 0.3640334263909608 w1:0.028306065127253532\n",
      "Average loss epoch 435: 0.37091728928498924 w1:0.023833435028791428\n",
      "Average loss epoch 436: 0.3875294583849609 w1:0.02174711599946022\n",
      "Average loss epoch 437: 0.3838984437752515 w1:0.03169034421443939\n",
      "Average loss epoch 438: 0.42197291483171284 w1:0.031004585325717926\n",
      "Average loss epoch 439: 0.3891843124292791 w1:0.033018603920936584\n",
      "Average loss epoch 440: 0.3756940132007003 w1:0.04058355093002319\n",
      "Average loss epoch 441: 0.3765537696890533 w1:0.03467398136854172\n",
      "Average loss epoch 442: 0.3620014931075275 w1:0.041363783180713654\n",
      "Average loss epoch 443: 0.3732882409822196 w1:0.03460758551955223\n",
      "Average loss epoch 444: 0.3752587747294456 w1:0.03966759517788887\n",
      "Average loss epoch 445: 0.3966078592929989 w1:0.03663589432835579\n",
      "Average loss epoch 446: 0.4216450974345207 w1:0.03135993704199791\n",
      "Average loss epoch 447: 0.43767398805357516 w1:0.02892756648361683\n",
      "Average loss epoch 448: 0.46691095642745495 w1:0.02674137055873871\n",
      "Average loss epoch 449: 0.407320246566087 w1:0.01498940959572792\n",
      "Average loss epoch 450: 0.39095707377418876 w1:0.023326992988586426\n",
      "Average loss epoch 451: 0.3702553422190249 w1:0.028379833325743675\n",
      "Average loss epoch 452: 0.3775980470236391 w1:0.03359086811542511\n",
      "Average loss epoch 453: 0.36202789610251784 w1:0.033666569739580154\n",
      "Average loss epoch 454: 0.37313577462919056 w1:0.03633122518658638\n",
      "Average loss epoch 455: 0.3669039427768439 w1:0.03795754164457321\n",
      "Average loss epoch 456: 0.37013787496834993 w1:0.03334147483110428\n",
      "Average loss epoch 457: 0.3608891007024795 w1:0.03762851282954216\n",
      "Average loss epoch 458: 0.3692253567278385 w1:0.033828482031822205\n",
      "Average loss epoch 459: 0.37170002539642155 w1:0.03390219435095787\n",
      "Average loss epoch 460: 0.3633982005994767 w1:0.04055972397327423\n",
      "Average loss epoch 461: 0.3647192781791091 w1:0.033029403537511826\n",
      "Average loss epoch 462: 0.36407437617890537 w1:0.040397096425294876\n",
      "Average loss epoch 463: 0.3856014225166291 w1:0.03924800083041191\n",
      "Average loss epoch 464: 0.38032026984728873 w1:0.037589095532894135\n",
      "Average loss epoch 465: 0.3722528575453907 w1:0.036155492067337036\n",
      "Average loss epoch 466: 0.3610933069139719 w1:0.03508425131440163\n",
      "Average loss epoch 467: 0.3619834980927408 w1:0.0330316536128521\n",
      "Average loss epoch 468: 0.35791597072966397 w1:0.03734187036752701\n",
      "Average loss epoch 469: 0.374944367678836 w1:0.03397541493177414\n",
      "Average loss epoch 470: 0.37797968182712793 w1:0.03544462472200394\n",
      "Average loss epoch 471: 0.376353457570076 w1:0.04114264249801636\n",
      "Average loss epoch 472: 0.37309074914082885 w1:0.03894689679145813\n",
      "Average loss epoch 473: 0.3860256851185113 w1:0.03783531114459038\n",
      "Average loss epoch 474: 0.37861375231295824 w1:0.04106993228197098\n",
      "Average loss epoch 475: 0.3741093296557665 w1:0.0385892428457737\n",
      "Average loss epoch 476: 0.3610224255826324 w1:0.03741941601037979\n",
      "Average loss epoch 477: 0.36544829909689724 w1:0.03722531720995903\n",
      "Average loss epoch 478: 0.363421096932143 w1:0.037558212876319885\n",
      "Average loss epoch 479: 0.3795215436257422 w1:0.038009267300367355\n",
      "Average loss epoch 480: 0.36635987320914865 w1:0.03719056770205498\n",
      "Average loss epoch 481: 0.37140028923749924 w1:0.039164524525403976\n",
      "Average loss epoch 482: 0.3597202617675066 w1:0.03787079453468323\n",
      "Average loss epoch 483: 0.3529282985255122 w1:0.04038393124938011\n",
      "Average loss epoch 484: 0.3496242677792907 w1:0.036538947373628616\n",
      "Average loss epoch 485: 0.3564413166604936 w1:0.03461559861898422\n",
      "Average loss epoch 486: 0.36179997585713863 w1:0.03746805340051651\n",
      "Average loss epoch 487: 0.3895923178642988 w1:0.03776496648788452\n",
      "Average loss epoch 488: 0.3974574152380228 w1:0.043938785791397095\n",
      "Average loss epoch 489: 0.37712373537942767 w1:0.043975237756967545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss epoch 490: 0.3673998904414475 w1:0.04277825355529785\n",
      "Average loss epoch 491: 0.37291251542046666 w1:0.036991775035858154\n",
      "Average loss epoch 492: 0.3826207430101931 w1:0.04998079314827919\n",
      "Average loss epoch 493: 0.3829288687556982 w1:0.050966039299964905\n",
      "Average loss epoch 494: 0.3800260794814676 w1:0.039147622883319855\n",
      "Average loss epoch 495: 0.37174551328644156 w1:0.05225830525159836\n",
      "Average loss epoch 496: 0.41197336092591286 w1:0.05030740424990654\n",
      "Average loss epoch 497: 0.3973605721257627 w1:0.04389108344912529\n",
      "Average loss epoch 498: 0.3954548202455044 w1:0.044894300401210785\n",
      "Average loss epoch 499: 0.42324177036061883 w1:0.03413090109825134\n",
      "Average loss epoch 500: 0.41909094620496035 w1:0.032173652201890945\n",
      "Average loss epoch 501: 0.421998496633023 w1:0.03652212396264076\n",
      "Average loss epoch 502: 0.38857441931031644 w1:0.04479243978857994\n",
      "Average loss epoch 503: 0.3713708915747702 w1:0.04607373848557472\n",
      "Average loss epoch 504: 0.3708572145551443 w1:0.04565399885177612\n",
      "Average loss epoch 505: 0.3733469257131219 w1:0.04890064150094986\n",
      "Average loss epoch 506: 0.3604534638579935 w1:0.045616138726472855\n",
      "Average loss epoch 507: 0.35043279360979795 w1:0.044205017387866974\n",
      "Average loss epoch 508: 0.3553691669367254 w1:0.04479517042636871\n",
      "Average loss epoch 509: 0.3544875127263367 w1:0.04474152624607086\n",
      "Average loss epoch 510: 0.35270914947614074 w1:0.04369621351361275\n",
      "Average loss epoch 511: 0.35369140445254743 w1:0.044662345200777054\n",
      "Average loss epoch 512: 0.3534236098639667 w1:0.04388512670993805\n",
      "Average loss epoch 513: 0.3654122119769454 w1:0.04679451882839203\n",
      "Average loss epoch 514: 0.3704835381358862 w1:0.04186811298131943\n",
      "Average loss epoch 515: 0.3811045871116221 w1:0.04734760522842407\n",
      "Average loss epoch 516: 0.36749050742946565 w1:0.04237745702266693\n",
      "Average loss epoch 517: 0.3694007850717753 w1:0.04065706580877304\n",
      "Average loss epoch 518: 0.36079987580887973 w1:0.0409964993596077\n",
      "Average loss epoch 519: 0.3597941333428025 w1:0.04023096710443497\n",
      "Average loss epoch 520: 0.3555980487726629 w1:0.04332483932375908\n",
      "Average loss epoch 521: 0.3556972327642143 w1:0.041631631553173065\n",
      "Average loss epoch 522: 0.3530670830514282 w1:0.042561959475278854\n",
      "Average loss epoch 523: 0.3629476185888052 w1:0.04477508366107941\n",
      "Average loss epoch 524: 0.36303843138739467 w1:0.04403732717037201\n",
      "Average loss epoch 525: 0.36320570297539234 w1:0.04409608989953995\n",
      "Average loss epoch 526: 0.3649268632289022 w1:0.040834229439496994\n",
      "Average loss epoch 527: 0.39340360229834914 w1:0.04763873666524887\n",
      "Average loss epoch 528: 0.3804671191610396 w1:0.047739408910274506\n",
      "Average loss epoch 529: 0.36912979930639267 w1:0.05163576826453209\n",
      "Average loss epoch 530: 0.35861190827563405 w1:0.04800104349851608\n",
      "Average loss epoch 531: 0.373344199731946 w1:0.04866130277514458\n",
      "Average loss epoch 532: 0.3580140150152147 w1:0.04719610884785652\n",
      "Average loss epoch 533: 0.360688284272328 w1:0.049657490104436874\n",
      "Average loss epoch 534: 0.3561051497235894 w1:0.04545146971940994\n",
      "Average loss epoch 535: 0.34497922752052546 w1:0.04905347526073456\n",
      "Average loss epoch 536: 0.3537473473697901 w1:0.03916872665286064\n",
      "Average loss epoch 537: 0.3792054585646838 w1:0.05012309551239014\n",
      "Average loss epoch 538: 0.3613152951002121 w1:0.04521904140710831\n",
      "Average loss epoch 539: 0.3583894311450422 w1:0.05148281157016754\n",
      "Average loss epoch 540: 0.353839028859511 w1:0.048371680080890656\n",
      "Average loss epoch 541: 0.35652626887895167 w1:0.049630001187324524\n",
      "Average loss epoch 542: 0.3591992510482669 w1:0.04902909696102142\n",
      "Average loss epoch 543: 0.38983204076066613 w1:0.04617534205317497\n",
      "Average loss epoch 544: 0.38978791143745184 w1:0.04699821397662163\n",
      "Average loss epoch 545: 0.3902290135156363 w1:0.05610116571187973\n",
      "Average loss epoch 546: 0.3732498907484114 w1:0.046018436551094055\n",
      "Average loss epoch 547: 0.35594267630949616 w1:0.041941531002521515\n",
      "Average loss epoch 548: 0.3503617672249675 w1:0.04944644495844841\n",
      "Average loss epoch 549: 0.3811171103734523 w1:0.049074362963438034\n",
      "Average loss epoch 550: 0.38400291185826063 w1:0.04220542311668396\n",
      "Average loss epoch 551: 0.354888379573822 w1:0.04735531285405159\n",
      "Average loss epoch 552: 0.3685182388871908 w1:0.04631632938981056\n",
      "Average loss epoch 553: 0.35985481552779675 w1:0.0466143824160099\n",
      "Average loss epoch 554: 0.37277666572481394 w1:0.0484420582652092\n",
      "Average loss epoch 555: 0.35760520957410336 w1:0.03924267739057541\n",
      "Average loss epoch 556: 0.35180684574879706 w1:0.05041947960853577\n",
      "Average loss epoch 557: 0.36025496013462543 w1:0.04804135113954544\n",
      "Average loss epoch 558: 0.3693018511403352 w1:0.049268268048763275\n",
      "Average loss epoch 559: 0.3738416063133627 w1:0.05204993858933449\n",
      "Average loss epoch 560: 0.375231008278206 w1:0.0510425791144371\n",
      "Average loss epoch 561: 0.3590667936950922 w1:0.051179010421037674\n",
      "Average loss epoch 562: 0.4129457164090127 w1:0.043526239693164825\n",
      "Average loss epoch 563: 0.40060508740134537 w1:0.04223966971039772\n",
      "Average loss epoch 564: 0.42870754981413484 w1:0.05030796676874161\n",
      "Average loss epoch 565: 0.46356648579239845 w1:0.0532987080514431\n",
      "Average loss epoch 566: 0.4417632659897208 w1:0.05512579157948494\n",
      "Average loss epoch 567: 0.4218730377033353 w1:0.060353223234415054\n",
      "Average loss epoch 568: 0.40936450846493244 w1:0.062784843146801\n",
      "Average loss epoch 569: 0.38037279760465026 w1:0.05195368081331253\n",
      "Average loss epoch 570: 0.35814180644229054 w1:0.05080799385905266\n",
      "Average loss epoch 571: 0.3517457456327975 w1:0.05345550552010536\n",
      "Average loss epoch 572: 0.3539417376741767 w1:0.052800972014665604\n",
      "Average loss epoch 573: 0.36067286995239556 w1:0.05258592590689659\n",
      "Average loss epoch 574: 0.37049452029168606 w1:0.05204026401042938\n",
      "Average loss epoch 575: 0.3932070415467024 w1:0.05468898266553879\n",
      "Average loss epoch 576: 0.36794353229925036 w1:0.055305857211351395\n",
      "Average loss epoch 577: 0.35576103860512376 w1:0.04588945582509041\n",
      "Average loss epoch 578: 0.36127926711924374 w1:0.05420631542801857\n",
      "Average loss epoch 579: 0.36350079346448183 w1:0.05432554706931114\n",
      "Average loss epoch 580: 0.35760757816024125 w1:0.05774708837270737\n",
      "Average loss epoch 581: 0.36098789260722697 w1:0.0578092597424984\n",
      "Average loss epoch 582: 0.35595730575732887 w1:0.048226431012153625\n",
      "Average loss epoch 583: 0.34906960162334144 w1:0.05247391015291214\n",
      "Average loss epoch 584: 0.3838876485824585 w1:0.0442100428044796\n",
      "Average loss epoch 585: 0.36815653927624226 w1:0.039653290063142776\n",
      "Average loss epoch 586: 0.3727145460434258 w1:0.042401909828186035\n",
      "Average loss epoch 587: 0.38190063112415373 w1:0.04302370548248291\n",
      "Average loss epoch 588: 0.3827177651692182 w1:0.051888998597860336\n",
      "Average loss epoch 589: 0.45626859180629253 w1:0.04094391316175461\n",
      "Average loss epoch 590: 0.3987100450322032 w1:0.03150743246078491\n",
      "Average loss epoch 591: 0.4096130575053394 w1:0.03433581069111824\n",
      "Average loss epoch 592: 0.4409835431724787 w1:0.036533698439598083\n",
      "Average loss epoch 593: 0.40952335949987173 w1:0.0481652207672596\n",
      "Average loss epoch 594: 0.40853113075718284 w1:0.046169981360435486\n",
      "Average loss epoch 595: 0.3610989220906049 w1:0.04631669074296951\n",
      "Average loss epoch 596: 0.3638500478118658 w1:0.05231022462248802\n",
      "Average loss epoch 597: 0.3384893503971398 w1:0.05317527428269386\n",
      "Average loss epoch 598: 0.3372042942792177 w1:0.04973095282912254\n",
      "Average loss epoch 599: 0.3360496899113059 w1:0.04937809705734253\n",
      "Average loss epoch 600: 0.3378608929924667 w1:0.05321182310581207\n",
      "Average loss epoch 601: 0.3613337236456573 w1:0.05027519911527634\n",
      "Average loss epoch 602: 0.35453919076826423 w1:0.052964676171541214\n",
      "Average loss epoch 603: 0.36549112165812403 w1:0.0502593107521534\n",
      "Average loss epoch 604: 0.3437422662973404 w1:0.04713284596800804\n",
      "Average loss epoch 605: 0.33880982967093587 w1:0.05029597505927086\n",
      "Average loss epoch 606: 0.34915639413520694 w1:0.04902699962258339\n",
      "Average loss epoch 607: 0.3487379658035934 w1:0.05413369461894035\n",
      "Average loss epoch 608: 0.3991644848138094 w1:0.04883043095469475\n",
      "Average loss epoch 609: 0.3815353661775589 w1:0.035589590668678284\n",
      "Average loss epoch 610: 0.3588892968837172 w1:0.03068368323147297\n",
      "Average loss epoch 611: 0.36526116519235075 w1:0.03326144814491272\n",
      "Average loss epoch 612: 0.34857540507800877 w1:0.04233263432979584\n",
      "Average loss epoch 613: 0.35053774050902575 w1:0.04293668270111084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss epoch 614: 0.3607076173648238 w1:0.04286846145987511\n",
      "Average loss epoch 615: 0.34952586772851646 w1:0.046872809529304504\n",
      "Average loss epoch 616: 0.3665946847759187 w1:0.04701468348503113\n",
      "Average loss epoch 617: 0.3547163854818791 w1:0.04532971978187561\n",
      "Average loss epoch 618: 0.3836285504512489 w1:0.048119522631168365\n",
      "Average loss epoch 619: 0.36339387425687164 w1:0.0465269573032856\n",
      "Average loss epoch 620: 0.34901002468541265 w1:0.0539366751909256\n",
      "Average loss epoch 621: 0.3809899149928242 w1:0.05118333548307419\n",
      "Average loss epoch 622: 0.36484773689880967 w1:0.05039519444108009\n",
      "Average loss epoch 623: 0.38298981124535203 w1:0.04989571124315262\n",
      "Average loss epoch 624: 0.39269666001200676 w1:0.03455658257007599\n",
      "Average loss epoch 625: 0.388624909799546 w1:0.05199047550559044\n",
      "Average loss epoch 626: 0.43680308759212494 w1:0.053145650774240494\n",
      "Average loss epoch 627: 0.3846966288983822 w1:0.04352029040455818\n",
      "Average loss epoch 628: 0.3609949378296733 w1:0.04218257591128349\n",
      "Average loss epoch 629: 0.3492605115752667 w1:0.042010754346847534\n",
      "Total time: 83.01604461669922 seconds\n",
      "[[ 0.04201075  0.03208289  0.02968143 ...  0.04667331 -0.01741006\n",
      "  -0.13085154]\n",
      " [-0.2326205   0.04528846 -0.3133841  ... -0.01785086  0.00778822\n",
      "  -0.08851139]\n",
      " [-0.02718424 -0.01408268  0.03821434 ... -0.02824965 -0.01753942\n",
      "  -0.16719487]\n",
      " ...\n",
      " [-0.01176358  0.01314314 -0.01284431 ...  0.07093251  0.01441923\n",
      "   0.1507017 ]\n",
      " [ 0.05599165  0.00190839 -0.00782319 ...  0.00745542  0.01447298\n",
      "   0.0578312 ]\n",
      " [-0.15673545  0.06209305 -0.10879953 ... -0.05093817 -0.02132773\n",
      "   0.68081033]]\n",
      "Accuracy 0.704\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "   \n",
    "    start_time = time.time()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # train the model n_epochs times\n",
    "    for i in range(n_epochs): \t\n",
    "        sess.run(train_init)\t# drawing samples from train_data\n",
    "        total_loss = 0\n",
    "        n_batches = 0\n",
    "        try:\n",
    "            while True:\n",
    "                _, l = sess.run([optimizer, loss])\n",
    "                total_loss += l\n",
    "                n_batches += 1\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            pass\n",
    "#         print()\n",
    "        print('Average loss epoch {0}: {1} w1:{2}'.format(i, total_loss/n_batches,sess.run(w1)[0,0]))\n",
    "    print('Total time: {0} seconds'.format(time.time() - start_time))\n",
    "\n",
    "    # test the model\n",
    "    sess.run(test_init)\t\t\t# drawing samples from test_data\n",
    "    total_correct_preds = 0\n",
    "    try:\n",
    "        while True:\n",
    "            accuracy_batch = sess.run(accuracy)\n",
    "            \n",
    "            total_correct_preds += accuracy_batch\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        pass\n",
    "    print(sess.run(w1))\n",
    "    print('Accuracy {0}'.format(total_correct_preds/n_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfgpu15",
   "language": "python",
   "name": "tfgpu15"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
